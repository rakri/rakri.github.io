\documentclass[solution,addpoints,12pt]{exam}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}

\newenvironment{Solution}{\begin{EnvFullwidth}\begin{solution}}{\end{solution}\end{EnvFullwidth}}

\printanswers
%\unframedsolutions
\pagestyle{headandfoot}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%% INSTRUCTIONS %%%%%%%%%%%%%%%%%%%%%
% * Fill in your name and roll number below

% * Answer in place (after each question)

% * Use \begin{solution} and \end{solution} to typeset
%   your answers.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Fill in the details below
\def\studentName{\textbf{TODO: Name}}
\def\studentRoll{\textbf{TODO: Roll}}

\firstpageheader{CS 6841 - Assignment 1}{}{\studentName, \studentRoll}
\firstpageheadrule

\newcommand{\brac}[1]{\left[ #1 \right]}
\newcommand{\curly}[1]{\left\{ #1 \right\}}
\newcommand{\paren}[1]{\left( #1 \right)}
\newcommand{\card}[1]{\left\lvert #1 \right\rvert}

\newcommand{\prob}{\operatorname{\mathbf{Pr}}}
\newcommand{\ex}{\operatorname{\mathbf{E}}}
\newcommand{\from}{\leftarrow}

\newcommand{\field}{\mathbb{F}}
\newcommand{\reals}{\mathbb{R}}
\renewcommand{\mod}{\operatorname{mod}}
\newcommand{\hashFamily}{\mathcal{H}}

\newcommand{\Yes}{\texttt{Yes}}
\newcommand{\No}{\texttt{No}}

\begin{document}

\begin{questions}


\question[10] \textbf{(Designing a Tournament)}  This question will help you understand the applications of Chernoff bound and Union bound more, as you'll deal with tuning parameters to optimize the efficiency of the system. You'll also get an understanding of why NBA tournaments are designed the way they are, with more repeated matches being played as we get closer to the finals. For example, in the NBA, the early rounds are \emph{best-of-five}, and the later rounds become \emph{best-of-seven}. You will understand why, and also learn how to design tournaments with $n$ participants, for large $n$.

Suppose there are $n$ teams, and they are totally ranked. That is, there is a well-defined best team, second ranked team and so on. It's just that we (the algorithm designer) don't know the ranking. Moreover, assume that for any given match between two players, the better ranked team will win the match with probability $p = \frac12 + \delta$, \emph{independent of all other matches between these players and all other players also}. Here $\delta$ is a small positive constant.

\begin{parts}
\part[2] Let $n$ be a power of two, and fix an arbitrary tournament tree starting with $n/2$ matches, then $n/4$ matches and so on. What is the probability that the best team wins the tournament?

  \begin{solution}
  \begin{proof}
  $1 + 1 = 2$.
  \end{proof}
  \end{solution}

\part[3] Use Chernoff bounds to bound the probability that the best team will not win the tournament, if each match-up occurs as a \emph{best-of-$k$} series. How many games do you end up conducting in total to get a $1-\epsilon$ probability of the best team winning?
  \begin{solution}
  \begin{proof}
  $1 + 1 = 2$.
  \end{proof}
  \end{solution}

\part[5] Now design a tournament with a total of $O_\epsilon(n)$ games to get $1-\epsilon$ probability of the best team winning eventually. $O_\epsilon(n)$ means $O(n)$ for all constant $\epsilon>0$.
  \begin{solution}
  \begin{proof}
  $1 + 1 = 2$.
  \end{proof}
  \end{solution}



\end{parts}



\question[25] \textbf{(Counting Distinct Elements)}  Universal hash families come in handy when designing \emph{streaming algorithms} that make a \emph{single pass} and use very little space in comparison to the size of the input stream.  Here, we will construct a streaming algorithm to estimate the number of distinct elements in the stream.  The technique here is from a seminal work of Alon, Matias and Szegedy (STOC 1996); the authors were awarded the G\"{o}del prize in 2005 for this work.

\begin{parts}
\part[5] Recall that for a prime $p$, and an integer $k$, where $1 \le k \le p$, the collection:
\[ \hashFamily_k = \curly{h_{ab}: x \to (ax + b)\; \mod k%
   \mid a,b \in \field_p, a \ne 0 } \]
is a $2$-universal hash family.  \textbf{Prove} the following lemma:

  \begin{lemma}  For every set $S \subseteq \field_p$,
  \begin{enumerate}
  \item if $\card{S} < k$, then
    \[ \prob_{h \from H_{4k}} \brac{\exists x \in S: h(x) = 0} < 1/4;\]
  \item while, if $\card{S} \ge 2k$, then
    \[ \prob_{h \from H_{4k}} \brac{\exists x \in S: h(x) = 0} \ge 3/8.\]
  \end{enumerate}
  \end{lemma}

  \begin{solution}
  \begin{proof}
  $1 + 1 = 2$.
  \end{proof}
  \end{solution}

\part[10] Consider a stream of integers: $x_1, x_2, \ldots$; where each $x_i \in [n]$.  For a parameter $k$, where $1 \le k \le n$, design a streaming algorithm with the following guarantees:
\begin{enumerate}

\item if the stream contains strictly less than $k$ distinct elements, the  output is \No{} with probability at least $1 - 1/n^2$;

\item while, if the stream contains at least $2k$ distinct elements, then the output is \Yes{} with probability at least $1 - 1/n^2$.

\end{enumerate}

The algorithm should proceed in three phases as in the template solution below.  Fill in the details of the algorithm \emph{in the given template};  you need not provide implementation details but should be precise in your description.

\begin{solution}
\begin{itemize}

\item \emph{Initialization}: (pre-processing done before making the pass)
  \begin{enumerate}
  \item TODO:  Fill in the steps.
  \end{enumerate}

\item \emph{Processing}: ($x \in [n]$ is the element to process)

\item \emph{Output}: (called after the input is processed)
\end{itemize}
\end{solution}

Prove the guarantees of the algorithm designed above and calculate the space used by the algorithm (in $O(\cdot)$ notation).

  \begin{solution}
  \begin{proof}
  $1 + 1 = 2$.
  \end{proof}
  \end{solution}

\part[10]  Using the above, design a streaming algorithm that outputs an estimate of the number of distinct elements, upto a factor $2$ with probability at least $1 - 1/n$ ($n$ is a parameter passed to the algorithm).  As before, the algorithm should be in three phases (and may use the above procedures).  Prove the guarantees and calculate the total space used by the algorithm.

\part[5 extra credit]  Show how the above algorithm can be modified to obtain a factor $(1 + \epsilon)$-approximate with high probability.

\part[10 extra credit]  Can you reduce the space even further while maintaining the guarantees as in part c?  The improvement should be asymptotic, and not just by a constant factor.

\end{parts}

\question[15] \textbf{(Locality Sensitive Hashing)}  Given a distance metric $d: X \times X \to \reals^{\ge 0}$, a LSH family is a collection:
\[ \hashFamily = \curly{\ h: X \to [M]\ } \]
such that, for all $x, y \in X$:
\begin{enumerate}
  \item if $d(x, y) \le R$, $$\prob_{h \from \hashFamily} \brac{h(x) = h(y)} \ge p_1;$$

  \item while, if $d(x, y) > cR$, $$\prob_{h \from \hashFamily} \brac{h(x) = h(y)} < p_2.$$

  \item moreover, this (collision) probability is a non-increasing function of $d(x, y).$
\end{enumerate}

Here, $R, c, p_1, p_2$ are parameters that determine the quality of the hash family.  As was outlined in class, Indyk and Motwani designed an algorithm to store $n$ data-points so that $c$-approximate near-neighbor queries may be answered in \emph{sub-linear} time.

Recall that the algorithm consists of two components:

\begin{itemize}
\item \textbf{Preprocessing}:  (given the data-points $x_1, \ldots, x_n$, and two integer parameters $k, l$ chosen appropriately.)

  \begin{enumerate}

  \item Choose $l$ hash functions, $g_1, \ldots, g_l \from \hashFamily^{k}$ and initialize hash tables for each of them.  In other words, each $g_i$ is the concatenation of $k$ (randomly chosen) hash functions from $\hashFamily$.

  \item Insert each data point in each of the hash functions.

  \end{enumerate}

\item \textbf{Query}: (given data-point $y$.)

  \begin{enumerate}

  \item Iterate over the points mapped to $g_i(y)$ for $1 \le i \le l$ in the hash table and output all points $x_j$ at distance at most $cR$.

  \item Abort the above search if more than $10l$ data-points have already been looked at among all the hash tables.

  \end{enumerate}

\end{itemize}

\begin{parts}
\part[3] Calculate the value of $k$ so that, if $x, y \in X$ satisfy $d(x, y) > cR$, then:
  \[ \prob_{g \from \hashFamily^k } \brac{ g(x) = g(y) } < 1/n. \]
Show hence that the probability of aborting the query procedure is at most $1/5$.

\part[6] For the value of $k$ calculated above, calculate the collision probability, under a random $g$, of a data-point $x$ that is indeed within distance $R$ from $y$.  Calculate $l$ such that the probability that none of the hash functions $g_i$ cause a collision between $x$ and $y$ is at most $1/5$.

\part[6]  State tha guarantees of the algorithm:  output, space-complexity, time-complexity and confidence for the values of $k,$ and $l$ calculated above.

\end{parts}
\end{questions}
\end{document} 