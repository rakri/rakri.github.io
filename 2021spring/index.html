
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="content-type" content="
  text/html; charset=us-ascii" />
  <title>CS6841: IITM Approximation Algorithms, Jan-May 2018</title>
<script src="ASCIIMathML.js" type="text/javascript">
</script>

<!--<style type="text/css" media="screen">
body { background-color: #F4F4F4;
   /* font-family: Georgia, "Times New Roman", Times, serif;
   font-size: 80%; */ /* Resets 1em to 10px */ 
   }
.notes {color: #333333;}
ul {color: #003380;}
ol {color: #983514;}
li {padding-top: 0.10em;}
h3 {color: #444444;}
</style>-->

</head>

<body onload="translate()">
<h2> CS6841: Approximation Algorithms, Jan-May 2021</h2>
<dl>
<dd> <b>Lecturer</b>: <a href="http://www.cs.cmu.edu/~ravishan">Ravishankar Krishnaswamy</a><br>
<dd> <b>TAs</b>: Anil and Girish 
<br>
<dd><b>Location</b>: C Slot On Google Meet 
</dl>

<hr>
<h3>Announcements</h3>

<ul>
<li> (13/1): The course evaluation will be based on roughly 4-5 homeworks, 1 end-sem, and scribe notes </li>
</ul>
<hr>

<!--
<h3>Homeworks</h3>

<ul>
 <li><a href="hws/hw1.pdf">Homework 1</a> (<a href="hws/hw1.tex">source file</a> for typsetting answers) </li>
 <li><a href="hws/hw2.pdf">Homework 2</a> (<a href="hws/hw2.tex">source file</a> for typsetting answers) </li>
 <li><a href="hws/hw3.pdf">Homework 3</a> (<a href="hws/hw3.tex">source file</a> for typsetting answers) </li>
 <li><a href="hws/hw4.pdf">Homework 4</a> (<a href="hws/hw4.tex">source file</a> for typsetting answers) </li>
 <li><a href="hws/endsem.pdf">Endsem Takehome Exam</a> (<a href="hws/endsem-6841.zip">source files</a> for typsetting answers) </li>
</ul>
<hr>
-->

<h3>Completed Lectures  (<a href="all.pdf">handwritten notes of all notes</a>)</h3>



<ul style="list-style: none;">
 <li><b> </b> (01/02/2021). Course Introduction.
 <i><ul>
   <li>Introduced approximation algorithms and explained why we study them. Saw Johnson's Algorithm for Max-3-SAT. </li>
 </ul></i>
</li>
 <br>


 <li><b> </b> (02/02/2021). Useful Probability (<a href="useful.pdf">handwritten notes</a>).
 <i><ul>
   <li>Introduced basic probabilistic tools useful in this course and elsewhere. </li>
 </ul></i>
</li>
 <br>
    
 <li><b> </b> (03/02/2021,05/02/2021). Linear Programming (<a href="useful.pdf">handwritten notes</a>).
 <i><ul>
   <li>Introduced linear programming and exlained their utility. </li>
   <li>Covered Basic Feasible Solutions and Duality. </li>
 </ul></i>
</li>
 <br>


 <li><b> </b> (08/02/2021-16/02/2021). The Set Cover Problem (<a href="setcover.pdf">handwritten notes</a>).
 <i><ul>
   <li> Introduced this fundamental problem, and showed an f-approximation by solving the LP, and also an `Primal Dual` f-approximation which does not need to solve the LP.</li>
   <li> Showed a O(log n)-approximation using Randomized Rounding.</li>
   <li> Analyzed the greedy algorithm for the problem to show a O(log n) approximation. </li>
   <li> Presented an improved `dual fitting' analysis of the greedy algorithm.</li>
   <li> Introducted th classical discrepancy problem to illustrate the power of Linear Programming BFS.</li>
 </ul></i>
</li>
 <br>

 <li><b> </b> (17/02/2021-19/02/2021) The Knapsack Problem (<a href="load.pdf">handwritten notes</a>).
 <i><ul>
   <li> Introducted this classical problem to illustrate the concept of PTAS, and the Dynamic Programming + Discretization approach.</li>
   <li> Finished the Discretization+DP-based FPTAS for Knapsack.</li>
 </ul></i>
</li>
 <br>


 <li><b> </b> (22/02/2021-05/03/2021) Machine Scheduling/Load Balancing (<a href="load.pdf">handwritten notes</a>).
 <i><ul>
   <li> Introducted this classical problem of minimizing makespan on identical machines to illustrate the greedy algorithm (which incidentally is an "online algorithm"), and started working towards a PTAS.</li>
   <li> Covered the ideas of guessing OPT and enumerating small instances to get PTAS for Makespan on identical machines.</li>
   <li> Introduced the ``unrelated machines scheduling'' problem and covered the natural LP relaxation.</li>
   <li> Covered the 2-approximation by solving the LP to find a BFS, followed by a tree-rounding.</li>
   <li> Covered another 2-approximation algorithm using the concept of ``iterative rounding''.</li>
   <li> Introduced and Proved Holder's Inequality for use in understanding l_p norms.</li>
   <li> Presented an online algorithm for Makespan on Unrelated Machines using a greedy algorithm on a l_p norm soft-max potential function.</li>
 </ul></i>
</li>
 <br>



<li><b> </b> (08/03/2021-26/03/2021) Clustering (<a href="clustering.pdf">handwritten notes</a>).
 <i><ul>
   <li> Introduced metric spaces, and the clustering problems.</li>
   <li> Presented the 2-approximation for the k-Center objective.</li>
   <li> Introduced the k-Median Objective and presented an LP relaxation for it.</li>
   <li> Presented the LP-rounding based 4-approximation which opens 2k centers instead of k (bi-criteria approximation algorithm).</li>
   <li> Presented a more involved <i>dependant rounding</i> idea which only opens k centers and has O(1)-approximation.</li>
   <li> Covered a primal-dual 3-approximation for the related facility location problem.</li>
   <li> Using this, we covered a 6-approximation for the k-median by using the Lagrangean Relaxation technique. </li>
 </ul></i>
</li>
 <br>


 <li><b> </b> (05/04/2021-16/04/2021) Dimension Reduction, Locality Sensitive Hashing (<a href="hashing.pdf">handwritten notes</a>).  
 <i><ul>
   <li> Introducted the Gaussian Random Variable and studied some useful properties of Gaussian vectors.</li>
   <li> Introducted the dimension reduction problem, and saw how Gaussian projections can preserve distances approximately.</li>
   <li> Introduced the Near-Neighbor Search problem and saw how a Locality Sensitive Hashing scheme and effeciently sovle it.</li>
   <li> Studied good LSH schemes for the Hamming distance metric.
 </ul></i>
</li>

 <br>
<li><b> </b> (19/04/2021-23/04/2021) Max-Cut and Semidefinite Programming (<a href="sdp.pdf">handwritten notes</a>). 
 <i><ul>
   <li> Studied a simple LP rounding for min cut.</li>
   <li> Saw how to model max-cut using a linear programming with infinitely many constraints, which is equivalent to SDP. </li>
   <li> Briefly saw the connection between these infinite linear constraints, vector inner-products and non-negative eigenvalues and used this connection to solve the SDP with the Ellipsoid method. </li>
   <li> Saw a simple rounding scheme (using connections to the LSH!) which converts vectors to bits and analyzed its performance.</li>
 </ul></i>
</li>
 <br>
<li><b> </b> (27/04/2021-30/04/2021) Differential Privacy (<a href="privacy.pdf">handwritten notes</a>). 
 <i><ul>
   <li> How do we model what it is to do data analysis while protecting individual privacy?</li>
   <li> Motivated the model of Differential Privacy and formally defined it. Saw how we intentionally add noise (and approximations) to preserve the privacy!</li>
   <li> Analyzed the Laplacian Mechanism for count queries and also the exponential mechanism for for outputs restricted to a range. </li>
 </ul></i>
</li>
 <br>
 <li><b> </b> (03/05/2021-07/05/2021) Hardness of Approximation (<a href="hardness.pdf">handwritten notes</a>). 
 <i><ul>
   <li> Like we showed a problem is NP-complete to model its complexity for decision problems, how do we get a similar measure for optimization problems?</li>
   <li> Introduced Gap problems as an intermediary waypoint between decision problems and optimization problems which will help in obtaining hardness of approximation for optimization problems.</li>
   <li> Stated the PCP theorem and showed the beautiful connection between the PCP viewpoint and NP-completeness of Gap3SAT. </li>
   <li> Introduced the LabelCover problem and outlined how we show hardness of other problems using GapLabelCover.
 </ul></i>
</li>


<br>



</ul>


<hr>

<i>Thanks to Anupam Gupta for webpage design, and scribe template.</i>

</body>
</html>
